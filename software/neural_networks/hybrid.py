# -*- coding: utf-8 -*-
"""Hybrid.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kmiFAoQxQxwdnzE84J5e5D1KRVaCc-1G

#Dependencias
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import absolute_import, division, print_function, unicode_literals

# Install TensorFlow
try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf
from tensorflow.keras import layers
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import datetime
from google.colab import drive
drive.mount('/content/gdrive')

# %load_ext tensorboard
print("Tensorflow version: "+tf.__version__)

initial_epoch = 0

"""#Configuración"""

batch_size = 100
epochs = 50
model_num = 'all'
model_type = 'torq'
root_path = 'gdrive/My Drive/ipn/AeroTTeam/data/Archives/'

"""# Arquitectura

## Entradas

### Características (Hélice)
"""

feature_input = layers.Input(batch_shape=(batch_size,4))

"""###Serie de tiempo (Mediciones)"""

series_input = layers.Input(batch_shape=(batch_size,10,1))

"""##Valor Inicial"""

measure_input = layers.Input( batch_shape=( batch_size,1) )

"""## Red Perceptron

### Inicializando memoria de largo plazo
"""

perc_layer_1_c = layers.Dense(32, activation='relu') (feature_input)
perc_layer_2_c = layers.Dense(64, activation='relu') (perc_layer_1_c)
perc_layer_3_c = layers.Dense(128, activation='linear') (perc_layer_2_c)
#zeroinput = layers.Input (batch_shape=(batch_size,128))

"""###Expandir Medicion"""

autoenc_1 = layers.Dense(64,activation='sigmoid', name='autoenc_1') (measure_input)
autoenc_2 = layers.Dense(128,activation='sigmoid', name='autoenc_2') (autoenc_1)

"""## Red Recurrente"""

rnn_layer_1 = layers.LSTM(128, recurrent_activation='relu', stateful=False ) (series_input, initial_state=[autoenc_2,perc_layer_3_c])

"""###Normalización"""

autoenc_3 = layers.Dense(64, activation='sigmoid', name='autoenc_3') (rnn_layer_1)
autoenc_4 = layers.Dense(1, activation='linear', name='autoenc_4') (autoenc_3)

"""## Cargar pesos del autoencoder"""

ae_1 = np.load(root_path+'autoencoder/1_64.npy', allow_pickle=True)
ae_2 = np.load(root_path+'autoencoder/2_128.npy', allow_pickle=True)
ae_3 = np.load(root_path+'autoencoder/3_64.npy', allow_pickle=True)
ae_4 = np.load(root_path+'autoencoder/4_1.npy', allow_pickle=True)

"""##Compilando Modelo"""

model = tf.keras.Model(inputs=[feature_input,series_input,measure_input], outputs=autoenc_4)

model.get_layer('autoenc_1').set_weights(ae_1)
model.get_layer('autoenc_1').trainable = False
model.get_layer('autoenc_2').set_weights(ae_2)
model.get_layer('autoenc_2').trainable = False
model.get_layer('autoenc_3').set_weights(ae_3)
model.get_layer('autoenc_3').trainable = False
model.get_layer('autoenc_4').set_weights(ae_4)
model.get_layer('autoenc_4').trainable = False

model.compile(loss='mean_squared_error', optimizer='adam', lr=0.001)
model.summary()

"""#Entrenamiento

##Cargar Dataset

##Definir Función de entrenamiento
"""

#Load Tensorboard
time = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
logdir = os.path.join(root_path+"logs", time + "_"+ model_num +"_"+model_type+"_b{}".format(batch_size) )
modeldir = os.path.join(root_path+"models/", time + "_"+ model_num +"_"+model_type+"_b{}.h".format(batch_size) )
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, update_freq="epoch", write_images=True)

def load_data ( root_path, model_type, model_num, data_type ):
  input_train = pd.read_csv(root_path + 'input_'+ model_num +'_'+data_type+'_rnn_r10.csv', header=None, dtype="Float32"  )
  output_train = pd.read_csv(root_path + 'output_'+ model_num +'_'+data_type+'_'+ model_type + '_rnn_r10.csv', header=None, dtype="Float32"  )

  samples = input_train.shape[0] - (input_train.shape[0] % batch_size)

  if model_type == 'rpm':
      param_num = 14
  elif model_type == 'pow':
      param_num = 15
  elif model_type == 'torq':
      param_num = 16
  
  input1 = input_train.iloc[0:samples,0:4].values #input 1: parametros de la hélice
  input2 = input_train.iloc[0:samples,4:14].values.reshape(samples,10,1) #input 2: serie de tiempo de viento
  input3 = input_train.iloc[0:samples,param_num].values #input 3: primer valor de medicion a predecir

  output = output_train[0:samples].values

  return [[input1,input2,input3],output]

input, output = load_data (root_path, model_type, model_num, "train")

"""##Entrenar"""

model.fit(x = input,
            y= output,
            batch_size=batch_size,
            epochs=epochs,
            validation_split = 0.1,
            callbacks=[tensorboard_callback],
            initial_epoch=initial_epoch,
            verbose=2)

initial_epoch = initial_epoch + epochs

"""#Resultados

##Guardar modelo
"""

model.save(modeldir)

"""##Cargar Modelo"""

#modeldir = root_path + 'models/' + '20191112-232146_056_rpm_b20.h'
#model = tf.keras.models.load_model (modeldir)

"""##Cargar Test Dataset"""

# input_test  = pd.read_csv(root_path + 'input_'+model_num+'_test_rnn_r10.csv', header=None, dtype="Float32" )
# output_test  = pd.read_csv(root_path + 'output_'+model_num+'_test_'+ model_type + '_rnn_r10.csv', header=None, dtype="Float32" )

# if model_type == 'rpm':
#     param_num = 14
# elif model_type == 'pow':
#     param_num = 15
# elif model_type == 'torq':
#     param_num = 16

# samples_test = input_test.shape[0] - (input_test.shape[0] % batch_size)

# input1_t = input_test.iloc[0:samples_test,0:4].values #input 1: parametros de la hélice
# input2_t = input_test.iloc[0:samples_test,4:14].values.reshape(samples_test,10,1) #input 2: serie de tiempo de viento
# input3_t = input_test.iloc[0:samples_test,param_num].values #input 3: primer valor de medicion a predecir
# output_t = output_test[0:samples_test].values
input_t, output_t = load_data (root_path, model_type, model_num, "test")

"""##Probar modelo con test dataset"""

predicted_values = model.predict(x = input)
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111)
ax.scatter(predicted_values,output, s=25, marker='o', edgecolors='k', facecolors='w', label ="real vs predicted")
plt.legend(loc='upper left')
ax.set_ylabel("real")
ax.set_xlabel("predicted")
plt.savefig(modeldir+"/scatter.png")
ax.figure.show()

plt.figure(figsize=(12,8))
plt.plot(output[0:300],marker='o')
plt.plot(predicted_values[0:300],marker='x')
plt.savefig(modeldir+"/comparison_r.png")

predicted_values = model.predict(x = input_t)
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111)
ax.scatter(predicted_values,output_t, s=25, marker='o', edgecolors='k', facecolors='w', label ="real vs predicted")
plt.legend(loc='upper left')
ax.set_ylabel("real")
ax.set_xlabel("predicted")
plt.savefig(modeldir+"/scatter_r.png")
ax.figure.show()

plt.figure(figsize=(12,8))
plt.plot(output_t[0:300],marker='o')
plt.plot(predicted_values[0:300],marker='x')
plt.savefig(modeldir+"/comparison_r.png")

#%tensorboard --logdir gdrive/My\ Drive/ipn/AeroTTeam/data/Archives/logs
#from tensorboard import notebook
#notebook.display()